# Guide de D√©ploiement - FuelBot

## üõ†Ô∏è Pr√©requis

### Syst√®me
- Python 3.13+
- Node.js (optionnel, pour frontend)
- Git

### Services Externes
- **Ollama** : Serveur LLM local
  - Mod√®le : `qwen3:30b`
  - URL : `http://localhost:11434`

---

## üì¶ Installation

### 1. Cloner le Projet
```bash
git clone <repository-url>
cd BootcampIA
```

### 2. Backend Setup

#### Environnement Virtuel (recommand√©)
```bash
cd backend
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

#### Installation D√©pendances
```bash
pip install -r requirements.txt
```

**Contenu `requirements.txt`** :
```txt
fastapi==0.109.0
uvicorn==0.27.0
pydantic==2.5.3
requests==2.31.0
python-dotenv==1.0.0
beautifulsoup4==4.12.3
lxml==5.1.0
```

#### Configuration
Cr√©er `.env` dans `/backend` :
```env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen3:30b
RENNES_LAT=48.1173
RENNES_LON=-1.6778
```

### 3. Frontend Setup
```bash
cd frontend
# Aucune installation n√©cessaire (Vanilla JS)
```

---

## üöÄ Lancement

### Backend

#### D√©veloppement
```bash
cd backend
python -m uvicorn app.main:app --reload --port 8000
```

**Ou avec le script** :
```bash
cd BootcampIA
python run_backend.py
```

#### Production
```bash
cd backend
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

**Avec Gunicorn** (Linux) :
```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker app.main:app --bind 0.0.0.0:8000
```

### Frontend

#### D√©veloppement
```bash
cd frontend
python -m http.server 3000
```

**Ou ouvrir directement** :
```bash
# Windows
start index.html

# Mac
open index.html

# Linux
xdg-open index.html
```

#### Production
H√©berger sur Nginx, Apache, ou service cloud (Vercel, Netlify).

---

## üê≥ Docker (Optionnel)

### Dockerfile Backend
```dockerfile
FROM python:3.13-slim

WORKDIR /app

COPY backend/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY backend/ .

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### docker-compose.yml
```yaml
version: '3.8'

services:
  backend:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    volumes:
      - ./backend/cache:/app/cache

  frontend:
    image: nginx:alpine
    ports:
      - "3000:80"
    volumes:
      - ./frontend:/usr/share/nginx/html
```

### Lancement
```bash
docker-compose up -d
```

---

## ‚òÅÔ∏è D√©ploiement Cloud

### Backend ‚Üí Railway / Render

#### 1. **Render.com**
```yaml
# render.yaml
services:
  - type: web
    name: fuelbot-api
    env: python
    buildCommand: pip install -r backend/requirements.txt
    startCommand: uvicorn app.main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: OLLAMA_BASE_URL
        value: http://your-ollama-server:11434
```

#### 2. **Railway**
```bash
railway login
railway init
railway up
```

### Frontend ‚Üí Vercel / Netlify

#### 1. **Vercel**
```bash
cd frontend
vercel --prod
```

#### 2. **Netlify**
```bash
cd frontend
netlify deploy --prod --dir=.
```

**Configuration** : Mettre √† jour URL backend dans `script.js` :
```javascript
const BACKEND_URL = "https://fuelbot-api.render.com";
```

---

## üîí S√©curit√© Production

### 1. CORS Restrictif
```python
# backend/app/main.py
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://votre-domaine.com"],  # ‚Üê Restreindre
    allow_credentials=True,
    allow_methods=["POST", "GET"],
    allow_headers=["Content-Type"],
)
```

### 2. Rate Limiting
```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/chat")
@limiter.limit("10/minute")
async def chat(request: ChatRequest):
    ...
```

### 3. Variables d'Environnement
Ne **jamais** commit `.env` :
```bash
echo ".env" >> .gitignore
```

### 4. HTTPS
- Utiliser Let's Encrypt (Certbot)
- Ou certificat cloud provider (Cloudflare, AWS)

---

## üìä Monitoring

### 1. Logs
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)
```

### 2. Health Check
```bash
curl http://localhost:8000/api/health
```

### 3. Prometheus (Optionnel)
```python
from prometheus_fastapi_instrumentator import Instrumentator

Instrumentator().instrument(app).expose(app)
```

---

## üß™ Tests Pr√©-D√©ploiement

### Backend
```bash
pytest tests/
```

### API Endpoints
```bash
# Health check
curl http://localhost:8000/api/health

# Chat endpoint
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Prix gazole", "latitude": 48.1104, "longitude": -1.6769}'
```

### Frontend
- Ouvrir navigateur ‚Üí DevTools ‚Üí Console
- V√©rifier g√©olocalisation
- Tester toutes les suggestions

---

## üêõ Troubleshooting

### Backend ne d√©marre pas
```bash
# V√©rifier port disponible
netstat -ano | findstr :8000

# Tuer processus si occup√©
taskkill /PID <PID> /F  # Windows
kill -9 <PID>            # Linux/Mac
```

### CORS Error
```
Access-Control-Allow-Origin...
```
‚Üí V√©rifier `allow_origins` dans `main.py`

### LLM Error
```
Connection refused to Ollama
```
‚Üí V√©rifier Ollama tourne : `curl http://localhost:11434`

### GPS non disponible
‚Üí Fallback automatique √† Rennes centre (48.1104, -1.6769)

---

## üìà Optimisations Production

### 1. Cache Redis
```python
import redis

cache = redis.Redis(host='localhost', port=6379)

def get_fuel_prices():
    cached = cache.get('fuel_prices')
    if cached:
        return json.loads(cached)
    
    data = scraper.fetch()
    cache.setex('fuel_prices', 3600, json.dumps(data))
    return data
```

### 2. CDN pour Frontend
- H√©berger assets statiques sur Cloudflare/AWS S3
- Activer compression Gzip/Brotli

### 3. Database
- Migrer cache JSON ‚Üí PostgreSQL/MongoDB
- Indexer sur `cp`, `ville`, `fuel_type`

---

## üîÑ CI/CD (Optionnel)

### GitHub Actions
```yaml
# .github/workflows/deploy.yml
name: Deploy

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Deploy Backend
        run: |
          ssh user@server "cd /app && git pull && systemctl restart fuelbot"
      
      - name: Deploy Frontend
        run: vercel --prod
```

---

## üìö Checklist D√©ploiement

- [ ] Variables d'environnement configur√©es
- [ ] CORS restreint au domaine production
- [ ] HTTPS activ√©
- [ ] Rate limiting configur√©
- [ ] Logs activ√©s
- [ ] Health check op√©rationnel
- [ ] Tests passent
- [ ] Cache optimis√©
- [ ] Monitoring configur√©
- [ ] Backup donn√©es planifi√©
